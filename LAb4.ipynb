{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9520d2",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4\n",
    "\n",
    "ФИО: Тенчурин Александр Андреевич \n",
    "\n",
    "Группа: БИВТ-21-4\n",
    "\n",
    "### План работы:\n",
    "1. Загрузить необходимые данные к себе и считать (read) их в переменную.\n",
    "2. Понять, у вас задача классификации (бинарной или многоклассовой) или регрессии.\n",
    "3. Сделать предобработку данных:  \n",
    "     1. Разделить выборку на тренировочную (train) и тестовую (test). \n",
    "     2. Проверить пропуски в данных. \n",
    "     3. Отнормировать численные переменные (`StandardScaler`, `MinMaxScaler`).\n",
    "     4. Закодировать категориальные признаки по одной из стратегий.\n",
    "4. Оформить данные в виде класса `Dataset` из библиотеки `torch` , а затем засунуть в `Dataloader`.\n",
    "5. Обучить на тренировочном множестве:\n",
    "     1. Очень простую однослойную нейросеть с оптимизатором `SGD`.\n",
    "     2. Нейросеть посложнее (с 1 скрытым слоем) с оптимизатором `Adam`.\n",
    "     3. Нейросеть еще сложнее (с 3+ скрытыми слоями) с оптимизатором `Adam`.\n",
    "6. Посчитайте loss на train и test множествах, в зависимости от эпохи обучения. Провизуализируйте это с помощью библиотеки `matplotlib` (выйдет так называемая **learning curve**, кривая обучения модели).\n",
    "6. Посчитайте метрики на train и test множествах (MAE)\n",
    "7. Сравните метрики относительно train/test, так и относительно разных моделей. Ответьте на следующие вопросы:\n",
    "     1. Какая модель справилась лучше с поставленной задачей?\n",
    "     2. Имеет ли место переобучение?\n",
    "     3. Имеет ли место недообучение?\n",
    "     4. Как можно улучшить метрики моделей?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b51062",
   "metadata": {},
   "source": [
    "## 1. Импорт данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "406597a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        4   0  11  11  \n",
       "1      5        3      3     1     1      3        2   9  11  11  \n",
       "2      4        3      2     2     3      3        6  12  13  12  \n",
       "3      3        2      2     1     1      5        0  14  14  14  \n",
       "4      4        3      2     1     2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('student-por.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d119028",
   "metadata": {},
   "source": [
    "## 2. Анализ задачи\n",
    "\n",
    "В целом перед нами стоит задача разработать модель, способную предсказывать успеваемость учащихся на основе доступных данных. Целевая переменная - число, мы хотим спрогнозировать финальную оценку студента, поэтому это задача регрессии. \n",
    "Какие основные факторы влияют на результаты тестирования? - Это тоже задача регрессии, где мы исследуем влияние различных факторов (пол, раса, уровень образования родителей, вид обеда, подготовка к экзаменам) на численные результаты тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d92464d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Вывод информации о типе данных в столбце \"G3\"\n",
    "print(df['G3'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e685f-9357-47eb-ab49-2f200381ac41",
   "metadata": {},
   "source": [
    "## 3 Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28945d18-66c7-4238-9180-e033bd6c9350",
   "metadata": {},
   "source": [
    "### A. Разделение выборки на тренировочную (train) и тестовую (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c5d723-b9d0-4524-adbb-4769a6d0cb4f",
   "metadata": {},
   "source": [
    "Разделение выборки на тренировочную и тестовую позволяет оценить производительность модели на новых, ранее не виденных данных. Это важно для проверки обобщающей способности модели и предотвращения переобучения. Переобучение возникает, когда модель хорошо работает на тренировочных данных, но плохо обобщается на новые данные. В Python, для разделения выборки на тренировочную и тестовую можно использовать функцию train_test_split из библиотеки scikit-learn. Эта функция случайным образом разбивает данные на две части с заданным соотношением. Обычно принято использовать пропорцию 70-80% для тренировочной выборки и 20-30% для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67a611d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность тренировочной выборки X_train: (519, 30)\n",
      "Размерность тестовой выборки X_test: (130, 30)\n",
      "Размерность тренировочной выборки y_train: (519, 3)\n",
      "Размерность тестовой выборки y_test: (130, 3)\n",
      "\n",
      "y_train: \n",
      "     G1  G2  G3\n",
      "332  18  18  18\n",
      "29   12  11  12\n",
      "302  10  11  12\n",
      "286  12  12  13\n",
      "554  10  11  10\n",
      "..   ..  ..  ..\n",
      "71   11   9  10\n",
      "106  10  10  10\n",
      "270  14  15  15\n",
      "435  10  10  10\n",
      "102  12  13  12\n",
      "\n",
      "[519 rows x 3 columns]\n",
      "\n",
      "y_test: \n",
      "     G1  G2  G3\n",
      "636  17  18  19\n",
      "220  11  11  12\n",
      "594  18  18  18\n",
      "429  10  11  11\n",
      "72   13  11  11\n",
      "..   ..  ..  ..\n",
      "514   7   6   7\n",
      "374  17  18  17\n",
      "444   9  10  11\n",
      "244  14  12  12\n",
      "601   8   8  10\n",
      "\n",
      "[130 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделение на матрицу признаков X и целевую переменную y\n",
    "X = df.drop(columns=['G1', 'G2', 'G3'])  # Удаляем столбцы, которые не являются признаками\n",
    "y = df[['G1', 'G2', 'G3']]  # Выбираем целевые переменные\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Проверка размерности выборок (первое число - количество записей, второе - количество используемых столбцов)\n",
    "print(\"Размерность тренировочной выборки X_train:\", X_train.shape)\n",
    "print(\"Размерность тестовой выборки X_test:\", X_test.shape)\n",
    "print(\"Размерность тренировочной выборки y_train:\", y_train.shape)\n",
    "print(\"Размерность тестовой выборки y_test:\", y_test.shape)\n",
    "print(\"\")\n",
    "print(\"y_train: \")\n",
    "print(y_train)\n",
    "print(\"\")\n",
    "print(\"y_test: \")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892f9e5-1e9c-4190-8f14-753fc26b15f0",
   "metadata": {},
   "source": [
    "## B. Делаем предобработку данных. Проверка на пропуски\n",
    "Следующим шагом идет проверка на пропуски в данных. Исходя из предыдущей лабораторной работы, пропусков в данном датасете нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0903fe82-1876-41ba-bf53-f93a2cbd5e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков в каждом столбце:\n",
      "school        0\n",
      "sex           0\n",
      "age           0\n",
      "address       0\n",
      "famsize       0\n",
      "Pstatus       0\n",
      "Medu          0\n",
      "Fedu          0\n",
      "Mjob          0\n",
      "Fjob          0\n",
      "reason        0\n",
      "guardian      0\n",
      "traveltime    0\n",
      "studytime     0\n",
      "failures      0\n",
      "schoolsup     0\n",
      "famsup        0\n",
      "paid          0\n",
      "activities    0\n",
      "nursery       0\n",
      "higher        0\n",
      "internet      0\n",
      "romantic      0\n",
      "famrel        0\n",
      "freetime      0\n",
      "goout         0\n",
      "Dalc          0\n",
      "Walc          0\n",
      "health        0\n",
      "absences      0\n",
      "G1            0\n",
      "G2            0\n",
      "G3            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = df.isna().sum()\n",
    "print(\"Количество пропусков в каждом столбце:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd127814-3035-43a4-8840-ef013bce2cc1",
   "metadata": {},
   "source": [
    "## C. Делаем предобработку данных. Отнормирование численных переменных\n",
    "Следующим шагом необходимо отнормировать численные переменные. Отнормирование численных переменных - это важный шаг в предобработке данных перед построением моделей машинного обучения. Этот процесс заключается в приведении значений численных признаков к одному масштабу или диапазону значений. \n",
    "\n",
    "Два основных метода нормирования численных переменных, которые часто используются:\n",
    "\n",
    "StandardScaler:\n",
    "Этот метод центрирует данные путем удаления среднего значения каждого признака, а затем масштабирует данные путем деления на стандартное отклонение. Результатом являются признаки со средним значением 0 и стандартным отклонением 1.\n",
    "\n",
    "MinMaxScaler:\n",
    "Этот метод преобразует данные так, чтобы они находились в заданном диапазоне, обычно от 0 до 1. Для этого каждое значение признака вычитается из минимального значения признака и затем делится на разницу между максимальным и минимальным значениями признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bbdf397-d7ab-4171-a645-cb25fe79c31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_standart_scaled: \n",
      "[[-0.73799923 -0.87481777  0.98793212 ... -0.21994878 -1.06834489\n",
      "  -0.78961576]\n",
      " [-0.73799923  1.14309521 -0.62953403 ...  2.07844218  1.01613255\n",
      "   0.06593869]\n",
      " [-0.73799923  1.14309521  0.98793212 ... -0.9860791  -0.37351908\n",
      "  -0.36183854]\n",
      " ...\n",
      " [-0.73799923  1.14309521 -0.62953403 ... -0.21994878  1.01613255\n",
      "   0.06593869]\n",
      " [ 1.35501497 -0.87481777 -1.4382671  ... -0.21994878  0.32130673\n",
      "  -0.78961576]\n",
      " [-0.73799923  1.14309521 -1.4382671  ... -0.9860791   1.01613255\n",
      "  -0.36183854]]\n",
      "\n",
      "X_train_minmax_scaled: \n",
      "[[0.         0.         0.42857143 ... 0.25       0.25       0.        ]\n",
      " [0.         1.         0.14285714 ... 1.         1.         0.125     ]\n",
      " [0.         1.         0.42857143 ... 0.         0.5        0.0625    ]\n",
      " ...\n",
      " [0.         1.         0.14285714 ... 0.25       1.         0.125     ]\n",
      " [1.         0.         0.         ... 0.25       0.75       0.        ]\n",
      " [0.         1.         0.         ... 0.         1.         0.0625    ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Создание копии данных для масштабирования\n",
    "X_train_encoded = X_train.copy()\n",
    "X_test_encoded = X_test.copy()\n",
    "\n",
    "# Применение Label Encoding к категориальным переменным\n",
    "label_encoder = LabelEncoder()\n",
    "for column in X_train.select_dtypes(include=['object']).columns:\n",
    "    X_train_encoded[column] = label_encoder.fit_transform(X_train[column])\n",
    "    X_test_encoded[column] = label_encoder.transform(X_test[column])\n",
    "\n",
    "# Инициализация и применение StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_standart_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_standart_scaled = scaler.transform(X_test_encoded)\n",
    "print(\"X_train_standart_scaled: \")\n",
    "print(X_train_standart_scaled)\n",
    "print(\"\")\n",
    "\n",
    "# Инициализация и применение MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_minmax_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_minmax_scaled = scaler.transform(X_test_encoded)\n",
    "print(\"X_train_minmax_scaled: \")\n",
    "print(X_train_minmax_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b3813-fbbe-4c26-be43-af89ddc80948",
   "metadata": {},
   "source": [
    "### D Кодировка категориальных признаков\n",
    "При работе с категориальными признаками в машинном обучении, часто нужно преобразовать их в числовой формат, потому что многие алгоритмы машинного обучения требуют числовых данных для работы.\n",
    "\n",
    "One-Hot Encoding: Этот метод создает бинарные (дамми) переменные для каждой категории в категориальном признаке. То есть каждая уникальная категория превращается в новый бинарный признак, который принимает значение 1, если наблюдение относится к этой категории, и 0 в противном случае. One-Hot Encoding предпочтителен, когда нет внутреннего порядка в категориях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a35584db-52f3-4b9e-b2a3-db9644a6d26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_one_hot_encoded: \n",
      "[[1. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "X_test_one_hot_encoded: \n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-Hot Encoding\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_one_hot_encoded = one_hot_encoder.fit_transform(X_train)\n",
    "X_test_one_hot_encoded = one_hot_encoder.transform(X_test)\n",
    "print(\"X_train_one_hot_encoded: \")\n",
    "print(X_train_one_hot_encoded.toarray())\n",
    "print(\"\")\n",
    "print(\"X_test_one_hot_encoded: \")\n",
    "print(X_test_one_hot_encoded.toarray())\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec9bd8-6d37-4666-8945-2e2d078b3295",
   "metadata": {},
   "source": [
    "## 4. Оформление данных в виде класса Dataset и помещение в Dataloader\n",
    "Для оформления данных тренировочной и тестовой выборок в виде класса Dataset из библиотеки PyTorch и последующего использования с помощью DataLoader потребуется создать подкласс torch.utils.data.Dataset и переопределить методы __init__, __len__ и __getitem__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1f35555-d6e9-4e90-983e-08996899fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.toarray(), dtype=torch.float32)  # Преобразуем разреженную матрицу в плотную\n",
    "        self.y = torch.tensor(y, dtype=torch.float32) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)  # Возвращаем размер датасета\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]  # Возвращаем признаки и соответствующую целевую переменную по индексу\n",
    "\n",
    "# Создание экземпляров тренировочной и тестовой выборок\n",
    "train_dataset = MyDataset(X_train_one_hot_encoded, X_train_minmax_scaled)\n",
    "test_dataset = MyDataset(X_test_one_hot_encoded, X_test_minmax_scaled)\n",
    "\n",
    "# Создание DataLoader для тренировочной и тестовой выборок\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2e6bf-8c1e-4582-857b-666caa8cf167",
   "metadata": {},
   "source": [
    "## 5 Обучение на тренировочном множестве "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39435a3-81d7-4d14-8bf3-7a714522cf88",
   "metadata": {},
   "source": [
    "### Обучение простой однослойной нейросети с оптимизатором SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab688c20-9619-44d8-bad1-08292c9ca717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/10, Loss: 0.26683708197540706\n",
      "Эпоха 2/10, Loss: 0.20242377950085533\n",
      "Эпоха 3/10, Loss: 0.2011614524655872\n",
      "Эпоха 4/10, Loss: 0.19260958830515543\n",
      "Эпоха 5/10, Loss: 0.19090828630659315\n",
      "Эпоха 6/10, Loss: 0.18878171841303507\n",
      "Эпоха 7/10, Loss: 0.18710550169150034\n",
      "Эпоха 8/10, Loss: 0.18556226955519783\n",
      "Эпоха 9/10, Loss: 0.1855775233772066\n",
      "Эпоха 10/10, Loss: 0.18113624387317234\n",
      "Обучение завершено\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\entak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([64, 30])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\entak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([7, 30])) that is different to the input size (torch.Size([7, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Определение класса модели\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)  # Однослойный линейный слой\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Определение параметров модели\n",
    "input_size = X_train_one_hot_encoded.shape[1]  # Размерность входных данных\n",
    "output_size = 1  # Размерность выходных данных (в нашем случае один выход)\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model_SimpleNet = SimpleNet(input_size, output_size)\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model_SimpleNet.parameters(), lr=learning_rate)\n",
    "\n",
    "# Обучение модели\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model_SimpleNet.train()  # Установка модели в режим обучения\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        # Прямой проход\n",
    "        outputs = model_SimpleNet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Обратное распространение и оптимизация\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f\"Эпоха {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}\")\n",
    "\n",
    "print(\"Обучение завершено\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c781e-afcf-4fbd-a196-663d08dd18fc",
   "metadata": {},
   "source": [
    "### В. Обучение на тренировочном множестве нейросети посложнее (с 1 скрытым слоем) с оптимизатором Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a962ee5-8357-477b-9cd4-5b4caa586c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [10/100], Loss: 0.1615\n",
      "Эпоха [20/100], Loss: 0.1534\n",
      "Эпоха [30/100], Loss: 0.1670\n",
      "Эпоха [40/100], Loss: 0.1703\n",
      "Эпоха [50/100], Loss: 0.1702\n",
      "Эпоха [60/100], Loss: 0.1724\n",
      "Эпоха [70/100], Loss: 0.1735\n",
      "Эпоха [80/100], Loss: 0.1624\n",
      "Эпоха [90/100], Loss: 0.1752\n",
      "Эпоха [100/100], Loss: 0.1598\n",
      "Обучение завершено\n"
     ]
    }
   ],
   "source": [
    "# Определение нейросети\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Параметры нейросети\n",
    "input_size = X_train_one_hot_encoded.shape[1]\n",
    "hidden_size = 64  # Размер скрытого слоя\n",
    "output_size = 1  # Размер выходного слоя\n",
    "\n",
    "# Создание нейросети\n",
    "model_NeuralNetwork = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Оптимизатор\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model_NeuralNetwork.parameters(), lr=learning_rate)\n",
    "\n",
    "# Функция потерь\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Обучение нейросети\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Переводим модель в режим обучения\n",
    "    model_NeuralNetwork.train()\n",
    "    \n",
    "    # Проходим по каждому батчу в тренировочном датасете\n",
    "    for inputs, targets in train_dataloader:\n",
    "        # Обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Передаем данные через нейросеть\n",
    "        outputs = model_NeuralNetwork(inputs)\n",
    "        \n",
    "        # Вычисляем функцию потерь\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Рассчитываем градиенты\n",
    "        loss.backward()\n",
    "        \n",
    "        # Обновляем параметры модели\n",
    "        optimizer.step()\n",
    "\n",
    "    # Выводим промежуточные результаты\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Эпоха [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Обучение завершено\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2f848-74ad-402a-b0f1-a0d5b2bb7a48",
   "metadata": {},
   "source": [
    "### С. Обучение на тренировочном множестве нейросети еще сложнее (с 3+ скрытыми слоями) с оптимизатором Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce4946e0-4c1a-4b06-8cb9-ad32a846a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [10/100], Loss: 0.1796\n",
      "Эпоха [20/100], Loss: 0.1679\n",
      "Эпоха [30/100], Loss: 0.1851\n",
      "Эпоха [40/100], Loss: 0.1630\n",
      "Эпоха [50/100], Loss: 0.1778\n",
      "Эпоха [60/100], Loss: 0.1609\n",
      "Эпоха [70/100], Loss: 0.1750\n",
      "Эпоха [80/100], Loss: 0.1708\n",
      "Эпоха [90/100], Loss: 0.1625\n",
      "Эпоха [100/100], Loss: 0.1718\n"
     ]
    }
   ],
   "source": [
    "# Определение нейросети\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Параметры нейросети\n",
    "input_size = X_train_one_hot_encoded.shape[1]\n",
    "hidden_sizes = [64, 32, 16]  # Размеры скрытых слоев\n",
    "output_size = 1  # Размер выходного слоя\n",
    "\n",
    "# Создание нейросети\n",
    "model_HardNeuralNetwork = NeuralNetwork(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Оптимизатор\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model_HardNeuralNetwork.parameters(), lr=learning_rate)\n",
    "\n",
    "# Функция потерь\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Обучение нейросети\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Переводим модель в режим обучения\n",
    "    model_HardNeuralNetwork.train()\n",
    "    \n",
    "    # Проходим по каждому батчу в тренировочном датасете\n",
    "    for inputs, targets in train_dataloader:\n",
    "        # Обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Передаем данные через нейросеть\n",
    "        outputs = model_HardNeuralNetwork(inputs)\n",
    "        \n",
    "        # Вычисляем функцию потерь\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Рассчитываем градиенты\n",
    "        loss.backward()\n",
    "        \n",
    "        # Обновляем параметры модели\n",
    "        optimizer.step()\n",
    "\n",
    "    # Выводим промежуточные результаты\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Эпоха [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d4d58-8158-4484-85aa-1ae6462afdd1",
   "metadata": {},
   "source": [
    "## 6. Подсчет loss на train и test множествах, в зависимости от эпохи обучения. Визуализация результата с помощью библиотеки matplotlib (выйдет так называемая learning curve, кривая обучения модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20dc13c4-13d0-45b0-9a6c-5c9513003aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\entak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([2, 30])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха [1/100], Обучающая потеря: 0.4383, Тестовая потеря: 0.3236\n",
      "Эпоха [2/100], Обучающая потеря: 0.2582, Тестовая потеря: 0.1859\n",
      "Эпоха [3/100], Обучающая потеря: 0.1842, Тестовая потеря: 0.1935\n",
      "Эпоха [4/100], Обучающая потеря: 0.1831, Тестовая потеря: 0.1766\n",
      "Эпоха [5/100], Обучающая потеря: 0.1764, Тестовая потеря: 0.1783\n",
      "Эпоха [6/100], Обучающая потеря: 0.1743, Тестовая потеря: 0.1753\n",
      "Эпоха [7/100], Обучающая потеря: 0.1733, Тестовая потеря: 0.1749\n",
      "Эпоха [8/100], Обучающая потеря: 0.1724, Тестовая потеря: 0.1747\n",
      "Эпоха [9/100], Обучающая потеря: 0.1720, Тестовая потеря: 0.1741\n",
      "Эпоха [10/100], Обучающая потеря: 0.1715, Тестовая потеря: 0.1739\n",
      "Эпоха [11/100], Обучающая потеря: 0.1711, Тестовая потеря: 0.1737\n",
      "Эпоха [12/100], Обучающая потеря: 0.1708, Тестовая потеря: 0.1734\n",
      "Эпоха [13/100], Обучающая потеря: 0.1706, Тестовая потеря: 0.1733\n",
      "Эпоха [14/100], Обучающая потеря: 0.1704, Тестовая потеря: 0.1732\n",
      "Эпоха [15/100], Обучающая потеря: 0.1702, Тестовая потеря: 0.1730\n",
      "Эпоха [16/100], Обучающая потеря: 0.1701, Тестовая потеря: 0.1729\n",
      "Эпоха [17/100], Обучающая потеря: 0.1700, Тестовая потеря: 0.1728\n",
      "Эпоха [18/100], Обучающая потеря: 0.1699, Тестовая потеря: 0.1727\n",
      "Эпоха [19/100], Обучающая потеря: 0.1698, Тестовая потеря: 0.1727\n",
      "Эпоха [20/100], Обучающая потеря: 0.1697, Тестовая потеря: 0.1726\n",
      "Эпоха [21/100], Обучающая потеря: 0.1697, Тестовая потеря: 0.1725\n",
      "Эпоха [22/100], Обучающая потеря: 0.1697, Тестовая потеря: 0.1725\n",
      "Эпоха [23/100], Обучающая потеря: 0.1696, Тестовая потеря: 0.1725\n",
      "Эпоха [24/100], Обучающая потеря: 0.1696, Тестовая потеря: 0.1724\n",
      "Эпоха [25/100], Обучающая потеря: 0.1696, Тестовая потеря: 0.1724\n",
      "Эпоха [26/100], Обучающая потеря: 0.1696, Тестовая потеря: 0.1724\n",
      "Эпоха [27/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1723\n",
      "Эпоха [28/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1723\n",
      "Эпоха [29/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1723\n",
      "Эпоха [30/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1723\n",
      "Эпоха [31/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1723\n",
      "Эпоха [32/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1723\n",
      "Эпоха [33/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1723\n",
      "Эпоха [34/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [35/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [36/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [37/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [38/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [39/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [40/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [41/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [42/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [43/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [44/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [45/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [46/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [47/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [48/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [49/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [50/100], Обучающая потеря: 0.1695, Тестовая потеря: 0.1722\n",
      "Эпоха [51/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [52/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [53/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [54/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [55/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [56/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [57/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [58/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [59/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [60/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [61/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [62/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [63/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [64/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [65/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [66/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [67/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [68/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [69/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [70/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [71/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [72/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [73/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [74/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [75/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [76/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [77/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [78/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [79/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [80/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [81/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [82/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [83/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [84/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [85/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [86/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [87/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [88/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [89/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [90/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [91/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [92/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [93/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [94/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [95/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [96/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [97/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [98/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [99/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n",
      "Эпоха [100/100], Обучающая потеря: 0.1694, Тестовая потеря: 0.1722\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Определение нейросети\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Функция для обучения модели и визуализации learning curve\n",
    "def train_model(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Переводим модель в режим обучения\n",
    "        model.train()\n",
    "        \n",
    "        # Обучение на тренировочном наборе данных\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_dataloader:\n",
    "            # Обнуляем градиент\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Передаем данные через нейросеть\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Вычисляем функцию потерь\n",
    "            loss = criterion(outputs, targets)\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Рассчитываем градиенты\n",
    "            loss.backward()\n",
    "            \n",
    "            # Обновляем параметры модели\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Сохраняем значение loss для обучающего набора данных\n",
    "        train_loss = train_loss / len(train_dataloader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Оценка loss на тестовом наборе данных\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        for inputs, targets in test_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "        test_loss = test_loss / len(test_dataloader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # Выводим результаты обучения на каждой эпохе\n",
    "        print(f'Эпоха [{epoch+1}/{num_epochs}], Обучающая потеря: {train_loss:.4f}, Тестовая потеря: {test_loss:.4f}')\n",
    "\n",
    "    # Визуализация learning curve\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Обучающая потеря', color='purple')\n",
    "    plt.plot(range(1, num_epochs+1), test_losses, label='Тестовая потеря', color='green')\n",
    "    plt.xlabel('Эпоха')\n",
    "    plt.ylabel('Потери')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Параметры нейросети\n",
    "input_size = X_train_one_hot_encoded.shape[1]\n",
    "hidden_sizes = [64, 32, 16]  # Размеры скрытых слоев\n",
    "output_size = 1  # Размер выходного слоя\n",
    "\n",
    "# Создание нейросети\n",
    "model = NeuralNetwork(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Оптимизатор\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Функция потерь\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Обучение нейросети и визуализация learning curve\n",
    "num_epochs = 100\n",
    "train_model(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fc237-2b0c-4d75-9236-89e44e502304",
   "metadata": {},
   "source": [
    "## 7. Подсчет метрики MAE на train и test множествах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5043169a-71cb-44e6-8c62-720c0c0d5c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE на train множестве SimpleNet: 11.3610\n",
      "MAE на test множестве SimpleNet: 11.5601\n",
      "MAE на train множестве NeuralNetwork: 11.1518\n",
      "MAE на test множестве NeuralNetwork: 11.3037\n",
      "MAE на train множестве HardNeuralNetwork: 11.1515\n",
      "MAE на test множестве HardNeuralNetwork: 11.2963\n"
     ]
    }
   ],
   "source": [
    "# Функция для вычисления MAE\n",
    "def calculate_mae(model, data_loader):\n",
    "    model.eval()  # Переводим модель в режим оценки (evaluation)\n",
    "    mae = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs)\n",
    "            mae += torch.abs(outputs - targets).sum().item()\n",
    "    mae = mae / len(data_loader.dataset)\n",
    "    return mae\n",
    "\n",
    "# Вычисление MAE на train и test множествах\n",
    "train_mae_SimpleNet = calculate_mae(model_SimpleNet, train_dataloader)\n",
    "test_mae_SimpleNet = calculate_mae(model_SimpleNet, test_dataloader)\n",
    "\n",
    "print(f'MAE на train множестве SimpleNet: {train_mae_SimpleNet:.4f}')\n",
    "print(f'MAE на test множестве SimpleNet: {test_mae_SimpleNet:.4f}')\n",
    "\n",
    "train_mae_NeuralNetwork = calculate_mae(model_NeuralNetwork, train_dataloader)\n",
    "test_mae_NeuralNetwork = calculate_mae(model_NeuralNetwork, test_dataloader)\n",
    "\n",
    "print(f'MAE на train множестве NeuralNetwork: {train_mae_NeuralNetwork:.4f}')\n",
    "print(f'MAE на test множестве NeuralNetwork: {test_mae_NeuralNetwork:.4f}')\n",
    "\n",
    "train_mae_HardNeuralNetwork = calculate_mae(model_HardNeuralNetwork, train_dataloader)\n",
    "test_mae_HardNeuralNetwork = calculate_mae(model_HardNeuralNetwork, test_dataloader)\n",
    "\n",
    "print(f'MAE на train множестве HardNeuralNetwork: {train_mae_HardNeuralNetwork:.4f}')\n",
    "print(f'MAE на test множестве HardNeuralNetwork: {test_mae_HardNeuralNetwork:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e6d04",
   "metadata": {},
   "source": [
    "### 8. Сравнение метрики относительно train/test, так и относительно разных моделей\n",
    " - MAE на train множестве SimpleNet: 11.7274\n",
    " - MAE на test множестве SimpleNet: 11.7296\n",
    " - MAE на train множестве NeuralNetwork: 11.2748\n",
    " - MAE на test множестве NeuralNetwork: 11.3701\n",
    " - MAE на train множестве HardNeuralNetwork: 11.2749\n",
    " - MAE на test множестве HardNeuralNetwork: 11.3453\n",
    "\n",
    "Лучше всего с задачей справилась сложная нейросеть с тремя скрытыми слоями, однако и модель с одним скрытым слоем показала не сильно худшие результаты. \n",
    "Рассмотрим пути улучшения метрик модели и точности в целом:\n",
    "\n",
    " - Использование более сложных моделей:\n",
    "В некоторых случаях простые модели могут быть недостаточно гибкими для описания сложных закономерностей в данных.\n",
    " - Выбор правильных признаков:\n",
    "Идентификация и выбор наиболее информативных признаков может улучшить производительность модели. Необходимо провести анализ важности признаков и оставить только самые значимые.\n",
    " - Увеличение объема данных:\n",
    "Дополнительные данные могут помочь модели лучше обобщать закономерности в данных. Нужно увеличить объем тренировочных данных, если это возможно.\n",
    " - Улучшение качества данных:\n",
    "Необходимо провести предварительную обработку данных, чтобы устранить шум, заполнить пропущенные значения и устранить выбросы. Чистые и качественные данные могут улучшить производительность модели."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
